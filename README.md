# Dzian Book

Этот репозиторий содержит три исходных текста в каталоге `core_texts`. Они служат основой для анализа трансцендентных когнитивных конструкций.

Дополнительные инструкции по работе с материалами приведены в файле [AGENTS.md](AGENTS.md). Там описана модель «10 мудрецов» и расширенный список аналитических методик.

## Структура репозитория

- `core_texts/` — PDF‑файлы с исходными текстами.
- `analyses/` — результаты OCR и аналитических разборов.
- `scripts/` — утилиты для обработки PDF, построения корпуса и глоссариев.
- `docs/` — материалы для GitHub Pages в формате вики.
- `discussions/` — заметки и протоколы обсуждений.
- `references/` — вспомогательные материалы и ссылки.

## Использование OCR

Для автоматической конвертации всех PDF в текст предусмотрен скрипт `scripts/ocr_all.py`. Он создаёт каталог `analyses/ocr_full` и сохраняет туда результаты распознавания по каждому файлу и странице. Запустить OCR можно командой:

```bash
sudo apt-get install poppler-utils tesseract-ocr tesseract-ocr-rus tesseract-ocr-eng
python3 scripts/ocr_all.py
```

По умолчанию используется `tesseract` с языковой моделью `rus+eng`. Для работы требуются утилиты `poppler-utils` (`pdftoppm`, `pdfinfo`) и пакет `tesseract-ocr`. Если `pdfinfo` отсутствует, скрипт использует библиотеку `PyPDF2` для определения числа страниц.

## Построение корпуса

После OCR можно получить лемматизированный корпус первой книги. Скрипт `scripts/build_corpus.py` извлекает леммы и части речи с помощью spaCy (`ru_core_news_sm`). Число обрабатываемых страниц задаётся переменной `MAX_PAGES`:

```bash
MAX_PAGES=5 python3 scripts/build_corpus.py
```

Файл `scripts/create_metadata.py` генерирует базу метаданных `analyses/metadata.csv` с указанием номера страницы и заготовками для разделов и примечаний.

## Глоссарии и Wiki

Скрипт `scripts/build_glossaries.py` формирует CSV-файлы с наиболее частотными терминами для каждой книги и общий файл `comparison.csv` для сравнения. Каталог `docs/` служит базой для GitHub Pages и позволяет оформлять материалы в формате вики.

## Веб-фронтенд

Для навигации по материалам проекта используется веб-интерфейс на основе Vite + React. Исходный код находится в каталоге `frontend`, а собранные файлы размещаются в `docs/web` и могут быть опубликованы через GitHub Pages. Интерфейс автоматически подгружает тексты анализа трёх книг и отображает их в формате небольшой википедии.

## Ядро истины

Скрипт `scripts/build_truth_core.py` объединяет ключевые инсайты из всех файлов анализа и формирует файл `analyses/truth_core.md`. Этот файл копируется в каталог `docs/` и доступен на GitHub Pages как центральное "ядро истины".

## Планы

- Провести декомпозицию и реконструкцию содержания текстов.
- Завершить анализ первой книги по модели «10 мудрецов» и сформировать когнитивное ядро.

За ходом развития проекта можно следить в [ROADMAP.md](ROADMAP.md) и [CHANGELOG.md](CHANGELOG.md).
